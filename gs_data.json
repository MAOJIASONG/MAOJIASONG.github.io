{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "J1cg8fIAAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "Maojia Song", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=J1cg8fIAAAAJ&citpid=5", "affiliation": "University of Leeds", "organization": 571725756079578255, "interests": ["Adaptive Intelligence", "Foundation Agents", "Multimodal Interaction", "Embodied AI"], "email_domain": "@leeds.ac.uk", "homepage": "https://maojiasong.github.io/", "citedby": 152, "publications": {"J1cg8fIAAAAJ:eQOLeE2rZwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Tongyi deepresearch technical report", "pub_year": 2025, "citation": "arXiv preprint arXiv:2510.24701, 2025", "author": "Tongyi DeepResearch Team and Baixuan Li and Bo Zhang and Dingchu Zhang and Fei Huang and Guangyu Li and Guoxin Chen and Huifeng Yin and Jialong Wu and Jingren Zhou and Kuan Li and Liangcai Su and Litu Ou and Liwen Zhang and Pengjun Xie and Rui Ye and Wenbiao Yin and Xinmiao Yu and Xinyu Wang and Xixi Wu and Xuanzhong Chen and Yida Zhao and Zhen Zhang and Zhengwei Tao and Zhongwang Zhang and Zile Qiao and Chenxi Wang and Donglei Yu and Gang Fu and Haiyang Shen and Jiayin Yang and Jun Lin and Junkai Zhang and Kui Zeng and Li Yang and Hailong Yin and Maojia Song and Ming Yan and Minpeng Liao and Peng Xia and Qian Xiao and Rui Min and Ruixue Ding and Runnan Fang and Shaowei Chen and Shen Huang and Shihang Wang and Shihao Cai and Weizhou Shen and Xiaobin Wang and Xin Guan and Xinyu Geng and Yingcheng Shi and Yuning Wu and Zhuo Chen and Zijian Li and Yong Jiang", "journal": "arXiv preprint arXiv:2510.24701", "abstract": "We present Tongyi DeepResearch, an agentic large language model, which is specifically designed for long-horizon, deep information-seeking research tasks. To incentivize autonomous deep research agency, Tongyi DeepResearch is developed through an end-to-end training framework that combines agentic mid-training and agentic post-training, enabling scalable reasoning and information seeking across complex tasks. We design a highly scalable data synthesis pipeline that is fully automatic, without relying on costly human annotation, and empowers all training stages. By constructing customized environments for each stage, our system enables stable and consistent interactions throughout. Tongyi DeepResearch, featuring 30.5 billion total parameters, with only 3.3 billion activated per token, achieves state-of-the-art performance across a range of agentic deep research benchmarks, including Humanity's Last Exam, BrowseComp, BrowseComp-ZH, WebWalkerQA, xbench-DeepSearch, FRAMES and xbench-DeepSearch-2510. We open-source the model, framework, and complete solutions to empower the community."}, "filled": true, "author_pub_id": "J1cg8fIAAAAJ:eQOLeE2rZwMC", "num_citations": 33, "citedby_url": "/scholar?hl=en&cites=1521622362299520568", "cites_id": ["1521622362299520568"], "pub_url": "https://arxiv.org/abs/2510.24701", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:OFYnA3rjHRUJ:scholar.google.com/", "cites_per_year": {"2025": 14, "2026": 19}}, "J1cg8fIAAAAJ:Y0pCki6q_DkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Tongyi DeepResearch: A New Era of Open-Source AI Researchers", "pub_year": 2025, "citation": "https://github.com/Alibaba-NLP/DeepResearch, 2025", "author": "Tongyi DeepResearch Team"}, "filled": true, "author_pub_id": "J1cg8fIAAAAJ:Y0pCki6q_DkC", "num_citations": 27, "citedby_url": "/scholar?hl=en&cites=680249518520032661,6826441936336510052", "cites_id": ["680249518520032661", "6826441936336510052"], "pub_url": "https://scholar.google.com/scholar?cluster=6826441936336510052&hl=en&oi=scholarr", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:lV0EPlW7cAkJ:scholar.google.com/", "cites_per_year": {"2025": 23, "2026": 4}}, "J1cg8fIAAAAJ:2osOgNQ5qMEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Measuring and enhancing trustworthiness of LLMs in RAG through grounded attributions and learning to refuse", "pub_year": 2024, "citation": "arXiv preprint arXiv:2409.11242, 2024", "author": "Maojia Song and Shang Hong Sim and Rishabh Bhardwaj and Hai Leong Chieu and Navonil Majumder and Soujanya Poria", "journal": "arXiv preprint arXiv:2409.11242", "abstract": "LLMs are an integral component of retrieval-augmented generation (RAG) systems. While many studies focus on evaluating the overall quality of end-to-end RAG systems, there is a gap in understanding the appropriateness of LLMs for the RAG task. To address this, we introduce Trust-Score, a holistic metric that evaluates the trustworthiness of LLMs within the RAG framework. Our results show that various prompting methods, such as in-context learning, fail to effectively adapt LLMs to the RAG task as measured by Trust-Score. Consequently, we propose Trust-Align, a method to align LLMs for improved Trust-Score performance. 26 out of 27 models aligned using Trust-Align substantially outperform competitive baselines on ASQA, QAMPARI, and ELI5. Specifically, in LLaMA-3-8b, Trust-Align outperforms FRONT on ASQA (up 12.56), QAMPARI (up 36.04), and ELI5 (up 17.69). Trust-Align also significantly enhances models' ability to correctly refuse and provide quality citations. We also demonstrate the effectiveness of Trust-Align across different open-weight models, including the LLaMA series (1b to 8b), Qwen-2.5 series (0.5b to 7b), and Phi3.5 (3.8b). We release our code at https://github.com/declare-lab/trust-align."}, "filled": true, "author_pub_id": "J1cg8fIAAAAJ:2osOgNQ5qMEC", "num_citations": 26, "citedby_url": "/scholar?hl=en&cites=14261566534983479602", "cites_id": ["14261566534983479602"], "pub_url": "https://arxiv.org/abs/2409.11242", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:MvFJ2jND68UJ:scholar.google.com/", "cites_per_year": {"2024": 1, "2025": 21, "2026": 4}}, "J1cg8fIAAAAJ:qjMakFHDy7sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "M-longdoc: A benchmark for multimodal super-long document understanding and a retrieval-aware tuning framework", "pub_year": 2025, "citation": "Proceedings of the 2025 Conference on Empirical Methods in Natural Language …, 2025", "author": "Yew Ken Chia and Liying Cheng and Hou Pong Chan and Maojia Song and Chaoqun Liu and Mahani Aljunied and Soujanya Poria and Lidong Bing", "conference": "Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing", "pages": "9244-9261"}, "filled": true, "author_pub_id": "J1cg8fIAAAAJ:qjMakFHDy7sC", "num_citations": 24, "citedby_url": "/scholar?hl=en&cites=12832942965180557061", "cites_id": ["12832942965180557061"], "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:BWdvjqLFF7IJ:scholar.google.com/", "cites_per_year": {"2025": 21, "2026": 2}}, "J1cg8fIAAAAJ:W7OEmFMy1HYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Scaling agents via continual pre-training", "pub_year": 2025, "citation": "arXiv preprint arXiv:2509.13310, 2025", "author": "Liangcai Su and Zhen Zhang and Guangyu Li and Zhuo Chen and Chenxi Wang and Maojia Song and Xinyu Wang and Kuan Li and Jialong Wu and Xuanzhong Chen and Zile Qiao and Zhongwang Zhang and Huifeng Yin and Shihao Cai and Runnan Fang and Zhengwei Tao and Wenbiao Yin and Chenxiong Qian and Yong Jiang and Pengjun Xie and Fei Huang and Jingren Zhou", "abstract": "Large language models (LLMs) have evolved into agentic systems capable of autonomous tool use and multi-step reasoning for complex problem-solving. However, post-training approaches building upon general-purpose foundation models consistently underperform in agentic tasks, particularly in open-source implementations. We identify the root cause: the absence of robust agentic foundation models forces models during post-training to simultaneously learn diverse agentic behaviors while aligning them to expert demonstrations, thereby creating fundamental optimization tensions. To this end, we are the first to propose incorporating Agentic Continual Pre-training (Agentic CPT) into the deep research agents training pipeline to build powerful agentic foundational models. Based on this approach, we develop a deep research agent model named AgentFounder. We evaluate our AgentFounder-30B on 10 benchmarks and achieve state-of-the-art performance while retains strong tool-use ability, notably 39.9% on BrowseComp-en, 43.3% on BrowseComp-zh, and 31.5% Pass@1 on HLE."}, "filled": true, "author_pub_id": "J1cg8fIAAAAJ:W7OEmFMy1HYC", "num_citations": 14, "citedby_url": "/scholar?hl=en&cites=12854362929563707341", "cites_id": ["12854362929563707341"], "pub_url": "https://arxiv.org/abs/2509.13310", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:zSeYpvreY7IJ:scholar.google.com/", "cites_per_year": {"2025": 11, "2026": 3}}, "J1cg8fIAAAAJ:d1gkVwhDpl0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Anti-attack intrusion detection model based on MPNN and traffic spatiotemporal characteristics", "pub_year": 2023, "citation": "Journal of Grid Computing 21 (4), 60, 2023", "author": "Jiazhong Lu and Jin Lan and Yuanyuan Huang and Maojia Song and Xiaolei Liu", "journal": "Journal of Grid Computing", "volume": "21", "number": "4", "pages": "60", "publisher": "Springer Netherlands", "abstract": "Considering the robustness and accuracy of conventional intrusion detection models are easily influenced by adversarial attacks, this work proposes an anti-attack intrusion detection model based on a message-passing neural network with traffic spatiotemporal features. Our model can not only effectively distinguish and correlate upstream and downstream traffics, but also clearly embody the relationship between different traffics from the same source node and destination node by the established graph structure. We also improve the model by utilising the characteristics of the existing network attacks, which indicates that the traffic spatiotemporal characteristics could achieve high accuracy on attack traffic detection. Compared to the previous model, extensive experiments show that our proposed model outperforms other similar models in performance. For the multi-classification tasks, our model can effectively …"}, "filled": true, "author_pub_id": "J1cg8fIAAAAJ:d1gkVwhDpl0C", "num_citations": 12, "citedby_url": "/scholar?hl=en&cites=8305554951981562649", "cites_id": ["8305554951981562649"], "pub_url": "https://link.springer.com/article/10.1007/s10723-023-09703-9", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:GftYXzlCQ3MJ:scholar.google.com/", "cites_per_year": {"2023": 1, "2024": 5, "2025": 6}}, "J1cg8fIAAAAJ:WF5omc3nYNoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Repurposing synthetic data for fine-grained search agent supervision", "pub_year": 2025, "citation": "arXiv preprint arXiv:2510.24694, 2025", "author": "Yida Zhao and Kuan Li and Xixi Wu and Liwen Zhang and Dingchu Zhang and Baixuan Li and Maojia Song and Zhuo Chen and Chenxi Wang and Xinyu Wang and Kewei Tu and Pengjun Xie and Jingren Zhou and Yong Jiang", "journal": "arXiv preprint arXiv:2510.24694", "abstract": "LLM-based search agents are increasingly trained on entity-centric synthetic data to solve complex, knowledge-intensive tasks. However, prevailing training methods like Group Relative Policy Optimization (GRPO) discard this rich entity information, relying instead on sparse, outcome-based rewards. This critical limitation renders them unable to distinguish informative \"near-miss\" samples-those with substantially correct reasoning but a flawed final answer-from complete failures, thus discarding valuable learning signals. We address this by leveraging the very entities discarded during training. Our empirical analysis reveals a strong positive correlation between the number of ground-truth entities identified during an agent's reasoning process and final answer accuracy. Building on this insight, we introduce Entity-aware Group Relative Policy Optimization (E-GRPO), a novel framework that formulates a dense entity-aware reward function. E-GRPO assigns partial rewards to incorrect samples proportional to their entity match rate, enabling the model to effectively learn from these \"near-misses\". Experiments on diverse question-answering (QA) and deep research benchmarks show that E-GRPO consistently and significantly outperforms the GRPO baseline. Furthermore, our analysis reveals that E-GRPO not only achieves superior accuracy but also induces more efficient reasoning policies that require fewer tool calls, demonstrating a more effective and sample-efficient approach to aligning search agents."}, "filled": true, "author_pub_id": "J1cg8fIAAAAJ:WF5omc3nYNoC", "num_citations": 3, "citedby_url": "/scholar?hl=en&cites=9284429002963729828", "cites_id": ["9284429002963729828"], "pub_url": "https://arxiv.org/abs/2510.24694", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:pL38t_zq2IAJ:scholar.google.com/", "cites_per_year": {"2025": 1, "2026": 2}}, "J1cg8fIAAAAJ:Tyk-4Ss8FVUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "LLMs Can't Handle Peer Pressure: Crumbling under Multi-Agent Social Interactions", "pub_year": 2025, "citation": "arXiv preprint arXiv:2508.18321, 2025", "author": "Maojia Song and Tej Deep Pala and Ruiwen Zhou and Weisheng Jin and Amir Zadeh and Chuan Li and Dorien Herremans and Soujanya Poria", "journal": "arXiv preprint arXiv:2508.18321", "abstract": "Large language models (LLMs) are increasingly integrated into multi-agent systems (MAS), where peer interactions shape individual decisions. While prior work has mainly examined conformity bias, we broaden the view to include how LLMs build rapport from prior interactions, discern and integrate high-quality peer information, and resist misleading inputs-abilities essential for achieving collective intelligence under complex social dynamics. We introduce KAIROS, a benchmark that simulates quiz-style collaboration with peer agents whose rapport levels and behaviours can be precisely controlled in both historical interactions and the current round. This unified setup enables systematic analysis of how rapport, peer actions, and the model's self-confidence jointly influence decision-making. Using KAIROS, we evaluate prompting, supervised fine-tuning, and reinforcement learning via Group Relative Policy Optimisation (GRPO). Results show that model scale is a primary factor moderating susceptibility to social influence: larger models are more resilient and benefit from prompting-based mitigation, whereas smaller models remain vulnerable. Only carefully configured GRPO training yields consistent robustness and performance gains for small models."}, "filled": true, "author_pub_id": "J1cg8fIAAAAJ:Tyk-4Ss8FVUC", "num_citations": 3, "citedby_url": "/scholar?hl=en&cites=18275405433659428251", "cites_id": ["18275405433659428251"], "pub_url": "https://arxiv.org/abs/2508.18321", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:m42DJ2pIn_0J:scholar.google.com/", "cites_per_year": {"2025": 3}}, "J1cg8fIAAAAJ:IjCSPb-OGe4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "The More, The Stronger? Investigating How Multi-Agent AI Shapes Human Opinions", "pub_year": 2025, "citation": "ICLR 2025 Workshop on Human-AI Coevolution, 2025", "author": "Tianqi Song and Yugin Tan and Zicheng Zhu and Maojia Song and Feng Yibin and Yi-Chieh Lee", "conference": "ICLR 2025 Workshop on Human-AI Coevolution", "abstract": "As AI agents become increasingly interactive, their potential to shape human opinions raises concerns about bias reinforcement, misinformation, and manipulation. While prior research has examined how individual AI agents influence users, it remains unclear whether multi-agent AI systems exert stronger influence, similar to human group effects. Drawing on social influence theory, we investigate whether a group of AI agents can amplify opinion shifts compared to a single agent. In an empirical study where participants discussed two paintings with either one or five AI agents, we found that multi-agent interactions led to significantly stronger opinion shifts. Participants aligned more closely with the AI group's expressed stance, suggesting that increasing the number of agents enhances social influence. These findings highlight both the opportunities and risks of multi-agent AI in shaping user opinions, with implications for persuasive and ethical AI design. Additionally, we identified several factors that may moderate the influence of multi-agent AI, including users' prior beliefs on the topic, perceived in-authenticity of AI-generated comments, and alignment between human and AI preferences. Considering these factors in future AI system design could help balance influence effectiveness with user autonomy and trust."}, "filled": true, "author_pub_id": "J1cg8fIAAAAJ:IjCSPb-OGe4C", "num_citations": 3, "citedby_url": "/scholar?hl=en&cites=7754410309846802175", "cites_id": ["7754410309846802175"], "pub_url": "https://openreview.net/forum?id=6zlttMWe4G", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:_54LmRcznWsJ:scholar.google.com/", "cites_per_year": {"2025": 1, "2026": 2}}, "J1cg8fIAAAAJ:9yKSN-GCB0IC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "FusionNet: a new perspective of CNN for image classification", "pub_year": 2022, "citation": "2022 3rd International Conference on Big Data, Artificial Intelligence and …, 2022", "author": "Maojia Song", "conference": "2022 3rd International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering (ICBAIE)", "pages": "639-647", "publisher": "IEEE", "abstract": "The civil livelihood plan is related to corn, or maize, as one of the most significant grain products that suffers from various kinds of diseases, resulting in a decline in production. Traditional manual examination for disease in terms of prevention and control is time-consuming with low efficiency. Therefore, this paper proposes a new architecture called FusionNet fully based on deep convolution network to improve the speed and accuracy of the classification of various maize diseases. Using focus splitting, identity shortcut, and multi-feature channel fusion, this model presents a new consideration of larger kernels utilized in concatenated for features that offer more effective receptive fields to facilitate the reduction of reused redundancy, especially for middle-layer abstract information, which could compensate for the shortage of feature selectivity of CNN. Moreover, the total number of parameters is limited by depth-wise …"}, "filled": true, "author_pub_id": "J1cg8fIAAAAJ:9yKSN-GCB0IC", "num_citations": 2, "citedby_url": "/scholar?hl=en&cites=15401652434721508861", "cites_id": ["15401652434721508861"], "pub_url": "https://ieeexplore.ieee.org/abstract/document/9985910/", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:_Q2btUmpvdUJ:scholar.google.com/", "cites_per_year": {"2024": 1, "2025": 1}}, "J1cg8fIAAAAJ:ufrVoPGSRksC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "AutoEnv: Automated Environments for Measuring Cross-Environment Agent Learning", "pub_year": 2025, "citation": "arXiv preprint arXiv:2511.19304, 2025", "author": "Jiayi Zhang and Yiran Peng and Fanqi Kong and Cheng Yang and Yifan Wu and Zhaoyang Yu and Jinyu Xiang and Jianhao Ruan and Jinlin Wang and Maojia Song and HongZhang Liu and Xiangru Tang and Bang Liu and Chenglin Wu and Yuyu Luo", "journal": "arXiv preprint arXiv:2511.19304", "abstract": "Humans naturally adapt to diverse environments by learning underlying rules across worlds with different dynamics, observations, and reward structures. In contrast, existing agents typically demonstrate improvements via self-evolving within a single domain, implicitly assuming a fixed environment distribution. Cross-environment learning has remained largely unmeasured: there is no standard collection of controllable, heterogeneous environments, nor a unified way to represent how agents learn. We address these gaps in two steps. First, we propose AutoEnv, an automated framework that treats environments as factorizable distributions over transitions, observations, and rewards, enabling low-cost (4.12 USD on average) generation of heterogeneous worlds. Using AutoEnv, we construct AutoEnv-36, a dataset of 36 environments with 358 validated levels, on which seven language models achieve 12-49% normalized reward, demonstrating the challenge of AutoEnv-36. Second, we formalize agent learning as a component-centric process driven by three stages of Selection, Optimization, and Evaluation applied to an improvable agent component. Using this formulation, we design eight learning methods and evaluate them on AutoEnv-36. Empirically, the gain of any single learning method quickly decrease as the number of environments increases, revealing that fixed learning methods do not scale across heterogeneous environments. Environment-adaptive selection of learning methods substantially improves performance but exhibits diminishing returns as the method space expands. These results highlight both the necessity and the current …"}, "filled": true, "author_pub_id": "J1cg8fIAAAAJ:ufrVoPGSRksC", "num_citations": 1, "citedby_url": "/scholar?hl=en&cites=10843241715214448888", "cites_id": ["10843241715214448888"], "pub_url": "https://arxiv.org/abs/2511.19304", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:-PgN2ePuepYJ:scholar.google.com/", "cites_per_year": {"2026": 1}}, "J1cg8fIAAAAJ:UebtZRa9Y70C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Demystifying deep search: a holistic evaluation with hint-free multi-hop questions and factorised metrics", "pub_year": 2025, "citation": "arXiv preprint arXiv:2510.05137, 2025", "author": "Maojia Song and Renhang Liu and Xinyu Wang and Yong Jiang and Pengjun Xie and Fei Huang and Jingren Zhou and Dorien Herremans and Soujanya Poria", "journal": "arXiv preprint arXiv:2510.05137", "abstract": "RAG (Retrieval-Augmented Generation) systems and web agents are increasingly evaluated on multi-hop deep search tasks, yet current practice suffers from two major limitations. First, most benchmarks leak the reasoning path in the question text, allowing models to follow surface cues rather than discover reasoning chains autonomously. Second, evaluation is typically reduced to a single pass rate, which collapses diverse behaviours into one score and obscures whether failures stem from inadequate search, poor knowledge use, or inappropriate refusal. To address these issues, we present WebDetective, a benchmark of hint-free multi-hop questions paired with a controlled Wikipedia sandbox that ensures full traceability of model actions, and a holistic evaluation framework that separates search sufficiency, knowledge utilisation, and refusal behaviour. Our evaluation of 25 state-of-the-art models reveals systematic weaknesses across all architectures: models struggle with knowledge utilisation despite having sufficient evidence and demonstrate near-absent appropriate refusal when evidence is lacking. These patterns expose a fundamental gap: today's systems excel at executing given reasoning paths but fail when required to discover them. We develop an agentic workflow, EvidenceLoop, that explicitly targets the challenges our benchmark identifies, incorporating verification loops and systematic evidence tracking that improve both search and synthesis capabilities. This baseline demonstrates that WebDetective's diagnostic framework can guide concrete architectural improvements, establishing our benchmark as a critical tool for …"}, "filled": true, "author_pub_id": "J1cg8fIAAAAJ:UebtZRa9Y70C", "num_citations": 1, "citedby_url": "/scholar?hl=en&cites=2658206233271798327", "cites_id": ["2658206233271798327"], "pub_url": "https://arxiv.org/abs/2510.05137", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:NwrlQXzY4yQJ:scholar.google.com/", "cites_per_year": {"2026": 1}}, "J1cg8fIAAAAJ:UeHWp8X0CEIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "PromptDistill: Query-based Selective Token Retention in Intermediate Layers for Efficient Large Language Model Inference", "pub_year": 2025, "citation": "arXiv preprint arXiv:2503.23274, 2025", "author": "Weisheng Jin and Maojia Song and Tej Deep Pala and Yew Ken Chia and Amir Zadeh and Chuan Li and Soujanya Poria", "journal": "arXiv preprint arXiv:2503.23274", "abstract": "As large language models (LLMs) tackle increasingly complex tasks and longer documents, their computational and memory costs during inference become a major bottleneck. To address this, we propose PromptDistill, a novel, training-free method that improves inference efficiency while preserving generation quality. PromptDistill identifies and retains the most informative tokens by leveraging attention interactions in early layers, preserving their hidden states while reducing the computational burden in later layers. This allows the model to focus on essential contextual information without fully processing all tokens. Unlike previous methods such as H2O and SnapKV, which perform compression only after processing the entire input, or GemFilter, which selects a fixed portion of the initial prompt without considering contextual dependencies, PromptDistill dynamically allocates computational resources to the most relevant tokens while maintaining a global awareness of the input. Experiments using our method and baseline approaches with base models such as LLaMA 3.1 8B Instruct, Phi 3.5 Mini Instruct, and Qwen2 7B Instruct on benchmarks including LongBench, InfBench, and Needle in a Haystack demonstrate that PromptDistill significantly improves efficiency while having minimal impact on output quality compared to the original models. With a single-stage selection strategy, PromptDistill effectively balances performance and efficiency, outperforming prior methods like GemFilter, H2O, and SnapKV due to its superior ability to retain essential information. Specifically, compared to GemFilter, PromptDistill achieves an overall  to  …"}, "filled": true, "author_pub_id": "J1cg8fIAAAAJ:UeHWp8X0CEIC", "num_citations": 1, "citedby_url": "/scholar?hl=en&cites=9266974857231082633", "cites_id": ["9266974857231082633"], "pub_url": "https://arxiv.org/abs/2503.23274", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:iSS8u4jomoAJ:scholar.google.com/", "cites_per_year": {"2026": 1}}, "J1cg8fIAAAAJ:u-x6o8ySG0sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Transformer Fault Diagnosis Based on PSO-RF Characterised by Modified CNN-encoder", "pub_year": 2022, "citation": "2022 IEEE 11th Data Driven Control and Learning Systems Conference (DDCLS …, 2022", "author": "Maojia Song and Yicheng Luo and Shixiao Liu and Jingwei Fan and Mingyue Li and Dong Liu", "conference": "2022 IEEE 11th Data Driven Control and Learning Systems Conference (DDCLS)", "pages": "300-305", "publisher": "IEEE", "abstract": "Oil-immersed transformer is one of the most important pieces of equipment in the power grid. Improving the performance of such transformer fault diagnosis to ensure a more stable power system is of great significance to safe operation. By analysing dissolved gases in oil, a fault diagnosis model based on Particle Swarm optimised Random Forest (PSO-RF), with features integrated by an improved CNN-encoder, is proposed. Firstly, the raw volume fraction of dissolved gases is processed by 1-dim Convolutional layers to form new combined features by machine. Secondly, current popular coded methods are integrated to produce final effective features that are sorted to obtain at least 90% of the information. Finally, feature vectors are applied to the fault diagnosis model based on PSO-RF. The experimental results show that the accuracy of the diagnosis model is achieved by 93.33% in the test set. Compared with …"}, "filled": true, "author_pub_id": "J1cg8fIAAAAJ:u-x6o8ySG0sC", "num_citations": 1, "citedby_url": "/scholar?hl=en&cites=6175682971576350721", "cites_id": ["6175682971576350721"], "pub_url": "https://ieeexplore.ieee.org/abstract/document/9858389/", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:Abg8RvFutFUJ:scholar.google.com/", "cites_per_year": {"2023": 1}}, "J1cg8fIAAAAJ:u5HHmVD_uO8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "The Mind Commands You: Combining Brain-Computer Interactions with Augmented Reality to Control Internet of Things (IoT) Tools, and Robotic Platforms", "pub_year": 2022, "citation": "2022 IEEE 5th International Conference on Electronics Technology (ICET …, 2022", "author": "Wang Haohong and Gao Shenghao and Zhao Yimin and Song Maojia and Wang Heng and Damien Constantine Rompapas", "conference": "2022 IEEE 5th International Conference on Electronics Technology (ICET)", "pages": "1026-1031", "publisher": "IEEE", "abstract": "Many researchers are exploring the use of Brain Computer Interfaces (BCI) in combination with Internet of Things (IoT) tools, and robotic control. However, the training and application process for BCI controls can be difficult to achieve partially due to the required double-attention of both the target matter, and the on screen feedback loop used during training. Enter Augmented Reality (AR), a technique for embedding computer generated content (CG) in the user’s view of the environment. In this research, we describe a system that explores the combination of a BCI training environment with AR technologies for both training and run time usage. We show the key advantage of this combination, allowing the user to focus directly on the subject matter. While our work is in the prototype phase, we show that this combination of AR and BCI has the potential to be effective in the training and usage of BCI interfaces."}, "filled": true, "author_pub_id": "J1cg8fIAAAAJ:u5HHmVD_uO8C", "num_citations": 1, "citedby_url": "/scholar?hl=en&cites=3343742152868183973", "cites_id": ["3343742152868183973"], "pub_url": "https://ieeexplore.ieee.org/abstract/document/9824583/", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:pT81qsVbZy4J:scholar.google.com/", "cites_per_year": {"2024": 1}}, "J1cg8fIAAAAJ:5nxA0vEk-isC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Epistemic Context Learning: Building Trust the Right Way in LLM-Based Multi-Agent Systems", "pub_year": 2026, "citation": "arXiv preprint arXiv:2601.21742, 2026", "author": "Ruiwen Zhou and Maojia Song and Xiaobao Wu and Sitao Cheng and Xunjian Yin and Yuxi Xie and Zhuoqun Hao and Wenyue Hua and Liangming Pan and Soujanya Poria and Min-Yen Kan", "journal": "arXiv preprint arXiv:2601.21742", "abstract": "Individual agents in multi-agent (MA) systems often lack robustness, tending to blindly conform to misleading peers. We show this weakness stems from both sycophancy and inadequate ability to evaluate peer reliability. To address this, we first formalize the learning problem of history-aware reference, introducing the historical interactions of peers as additional input, so that agents can estimate peer reliability and learn from trustworthy peers when uncertain. This shifts the task from evaluating peer reasoning quality to estimating peer reliability based on interaction history. We then develop Epistemic Context Learning (ECL): a reasoning framework that conditions predictions on explicitly-built peer profiles from history. We further optimize ECL by reinforcement learning using auxiliary rewards. Our experiments reveal that our ECL enables small models like Qwen 3-4B to outperform a history-agnostic baseline 8x its size (Qwen 3-30B) by accurately identifying reliable peers. ECL also boosts frontier models to near-perfect (100%) performance. We show that ECL generalizes well to various MA configurations and we find that trust is modeled well by LLMs, revealing a strong correlation in trust modeling accuracy and final answer quality."}, "filled": true, "author_pub_id": "J1cg8fIAAAAJ:5nxA0vEk-isC", "num_citations": 0, "pub_url": "https://arxiv.org/abs/2601.21742", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:tFuI6yfX-S8J:scholar.google.com/", "cites_per_year": {}}}, "citedby5y": 152, "hindex": 6, "hindex5y": 6, "i10index": 6, "i10index5y": 6, "cites_per_year": {"2023": 2, "2024": 8, "2025": 102, "2026": 39}, "updated": "2026-02-15 17:31:08.016321"}