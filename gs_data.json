{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "J1cg8fIAAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "Maojia Song", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=J1cg8fIAAAAJ&citpid=5", "affiliation": "University of Leeds", "organization": 571725756079578255, "interests": ["Adaptive Intelligence", "Natural Language Process", "Multimodal Interaction", "Question Answering"], "email_domain": "@leeds.ac.uk", "homepage": "https://maojiasong.github.io/", "citedby": 60, "publications": {"J1cg8fIAAAAJ:2osOgNQ5qMEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Measuring and enhancing trustworthiness of LLMs in RAG through grounded attributions and learning to refuse", "pub_year": 2024, "author": "Maojia Song and Shang Hong Sim and Rishabh Bhardwaj and Hai Leong Chieu and Navonil Majumder and Soujanya Poria", "journal": "arXiv preprint arXiv:2409.11242", "abstract": "LLMs are an integral component of retrieval-augmented generation (RAG) systems. While many studies focus on evaluating the overall quality of end-to-end RAG systems, there is a gap in understanding the appropriateness of LLMs for the RAG task. To address this, we introduce Trust-Score, a holistic metric that evaluates the trustworthiness of LLMs within the RAG framework. Our results show that various prompting methods, such as in-context learning, fail to effectively adapt LLMs to the RAG task as measured by Trust-Score. Consequently, we propose Trust-Align, a method to align LLMs for improved Trust-Score performance. 26 out of 27 models aligned using Trust-Align substantially outperform competitive baselines on ASQA, QAMPARI, and ELI5. Specifically, in LLaMA-3-8b, Trust-Align outperforms FRONT on ASQA (up 12.56), QAMPARI (up 36.04), and ELI5 (up 17.69). Trust-Align also significantly enhances models' ability to correctly refuse and provide quality citations. We also demonstrate the effectiveness of Trust-Align across different open-weight models, including the LLaMA series (1b to 8b), Qwen-2.5 series (0.5b to 7b), and Phi3.5 (3.8b). We release our code at https://github.com/declare-lab/trust-align."}, "filled": true, "author_pub_id": "J1cg8fIAAAAJ:2osOgNQ5qMEC", "num_citations": 17, "citedby_url": "/scholar?cites=14261566534983479602", "cites_id": ["14261566534983479602"], "pub_url": "https://arxiv.org/abs/2409.11242", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:MvFJ2jND68UJ:scholar.google.com/", "cites_per_year": {"2024": 1, "2025": 16}}, "J1cg8fIAAAAJ:qjMakFHDy7sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "M-longdoc: A benchmark for multimodal super-long document understanding and a retrieval-aware tuning framework", "pub_year": 2024, "author": "Yew Ken Chia and Liying Cheng and Hou Pong Chan and Chaoqun Liu and Maojia Song and Sharifah Mahani Aljunied and Soujanya Poria and Lidong Bing", "journal": "arXiv preprint arXiv:2411.06176", "abstract": "The ability to understand and answer questions over documents can be useful in many business and practical applications. However, documents often contain lengthy and diverse multimodal contents such as texts, figures, and tables, which are very time-consuming for humans to read thoroughly. Hence, there is an urgent need to develop effective and automated methods to aid humans in this task. In this work, we introduce M-LongDoc, a benchmark of 851 samples, and an automated framework to evaluate the performance of large multimodal models. We further propose a retrieval-aware tuning approach for efficient and effective multimodal document reading. Compared to existing works, our benchmark consists of more recent and lengthy documents with hundreds of pages, while also requiring open-ended solutions and not just extractive answers. To our knowledge, our training framework is the first to directly address the retrieval setting for multimodal long documents. To enable tuning open-source models, we construct a training corpus in a fully automatic manner for the question-answering task over such documents. Experiments show that our tuning approach achieves a relative improvement of 4.6% for the correctness of model responses, compared to the baseline open-source models. Our data, code, and models are available at https://multimodal-documents.github.io."}, "filled": true, "author_pub_id": "J1cg8fIAAAAJ:qjMakFHDy7sC", "num_citations": 15, "citedby_url": "/scholar?cites=12832942965180557061", "cites_id": ["12832942965180557061"], "pub_url": "https://arxiv.org/abs/2411.06176", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:BWdvjqLFF7IJ:scholar.google.com/", "cites_per_year": {"2024": 1, "2025": 13}}, "J1cg8fIAAAAJ:d1gkVwhDpl0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Anti-attack intrusion detection model based on MPNN and traffic spatiotemporal characteristics", "pub_year": 2023, "author": "Jiazhong Lu and Jin Lan and Yuanyuan Huang and Maojia Song and Xiaolei Liu", "journal": "Journal of Grid Computing", "volume": "21", "number": "4", "pages": "60", "publisher": "Springer Netherlands", "abstract": "Considering the robustness and accuracy of conventional intrusion detection models are easily influenced by adversarial attacks, this work proposes an anti-attack intrusion detection model based on a message-passing neural network with traffic spatiotemporal features. Our model can not only effectively distinguish and correlate upstream and downstream traffics, but also clearly embody the relationship between different traffics from the same source node and destination node by the established graph structure. We also improve the model by utilising the characteristics of the existing network attacks, which indicates that the traffic spatiotemporal characteristics could achieve high accuracy on attack traffic detection. Compared to the previous model, extensive experiments show that our proposed model outperforms other similar models in performance. For the multi-classification tasks, our model can effectively â€¦"}, "filled": true, "author_pub_id": "J1cg8fIAAAAJ:d1gkVwhDpl0C", "num_citations": 11, "citedby_url": "/scholar?cites=8305554951981562649", "cites_id": ["8305554951981562649"], "pub_url": "https://link.springer.com/article/10.1007/s10723-023-09703-9", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:GftYXzlCQ3MJ:scholar.google.com/", "cites_per_year": {"2023": 1, "2024": 5, "2025": 5}}, "J1cg8fIAAAAJ:Y0pCki6q_DkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Tongyi-DeepResearch", "pub_year": 2025, "author": "Tongyi DeepResearch Team"}, "filled": true, "author_pub_id": "J1cg8fIAAAAJ:Y0pCki6q_DkC", "num_citations": 7, "citedby_url": "/scholar?cites=680249518520032661", "cites_id": ["680249518520032661"], "pub_url": "https://scholar.google.com/scholar?cluster=680249518520032661&hl=en&oi=scholarr", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:lV0EPlW7cAkJ:scholar.google.com/", "cites_per_year": {"2025": 7}}, "J1cg8fIAAAAJ:W7OEmFMy1HYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Scaling agents via continual pre-training", "pub_year": 2025, "author": "Liangcai Su and Zhen Zhang and Guangyu Li and Zhuo Chen and Chenxi Wang and Maojia Song and Xinyu Wang and Kuan Li and Jialong Wu and Xuanzhong Chen and Zile Qiao and Zhongwang Zhang and Huifeng Yin and Shihao Cai and Runnan Fang and Zhengwei Tao and Wenbiao Yin and Chenxiong Qian and Yong Jiang and Pengjun Xie and Fei Huang and Jingren Zhou", "journal": "arXiv preprint arXiv:2509.13310", "abstract": "Large language models (LLMs) have evolved into agentic systems capable of autonomous tool use and multi-step reasoning for complex problem-solving. However, post-training approaches building upon general-purpose foundation models consistently underperform in agentic tasks, particularly in open-source implementations. We identify the root cause: the absence of robust agentic foundation models forces models during post-training to simultaneously learn diverse agentic behaviors while aligning them to expert demonstrations, thereby creating fundamental optimization tensions. To this end, we are the first to propose incorporating Agentic Continual Pre-training (Agentic CPT) into the deep research agents training pipeline to build powerful agentic foundational models. Based on this approach, we develop a deep research agent model named AgentFounder. We evaluate our AgentFounder-30B on 10 benchmarks and achieve state-of-the-art performance while retains strong tool-use ability, notably 39.9% on BrowseComp-en, 43.3% on BrowseComp-zh, and 31.5% Pass@1 on HLE."}, "filled": true, "author_pub_id": "J1cg8fIAAAAJ:W7OEmFMy1HYC", "num_citations": 3, "citedby_url": "/scholar?cites=12854362929563707341", "cites_id": ["12854362929563707341"], "pub_url": "https://arxiv.org/abs/2509.13310", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:zSeYpvreY7IJ:scholar.google.com/", "cites_per_year": {"2025": 3}}, "J1cg8fIAAAAJ:Tyk-4Ss8FVUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "LLMs Can't Handle Peer Pressure: Crumbling under Multi-Agent Social Interactions", "pub_year": 2025, "author": "Maojia Song and Tej Deep Pala and Weisheng Jin and Amir Zadeh and Chuan Li and Dorien Herremans and Soujanya Poria", "journal": "arXiv preprint arXiv:2508.18321", "abstract": "Large language models (LLMs) are increasingly deployed in multi-agent systems (MAS) as components of collaborative intelligence, where peer interactions dynamically shape individual decision-making. Although prior work has focused on conformity bias, we extend the analysis to examine how LLMs form trust from previous impressions, resist misinformation, and integrate peer input during interaction, key factors for achieving collective intelligence under complex social dynamics. We present KAIROS, a benchmark simulating quiz contests with peer agents of varying reliability, offering fine-grained control over conditions such as expert-novice roles, noisy crowds, and adversarial peers. LLMs receive both historical interactions and current peer responses, allowing systematic investigation into how trust, peer action, and self-confidence influence decisions. As for mitigation strategies, we evaluate prompting, supervised fine-tuning, and reinforcement learning, Group Relative Policy Optimisation (GRPO), across multiple models. Our results reveal that GRPO with multi-agent context combined with outcome-based rewards and unconstrained reasoning achieves the best overall performance, but also decreases the robustness to social influence compared to Base models. The code and datasets are available at: https://github.com/declare-lab/KAIROS."}, "filled": true, "author_pub_id": "J1cg8fIAAAAJ:Tyk-4Ss8FVUC", "num_citations": 3, "citedby_url": "/scholar?cites=18275405433659428251", "cites_id": ["18275405433659428251"], "pub_url": "https://arxiv.org/abs/2508.18321", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:m42DJ2pIn_0J:scholar.google.com/", "cites_per_year": {"2025": 3}}, "J1cg8fIAAAAJ:IjCSPb-OGe4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "The More, The Stronger? Investigating How Multi-Agent AI Shapes Human Opinions", "pub_year": 2025, "author": "Tianqi Song and Yugin Tan and Zicheng Zhu and Maojia Song and Feng Yibin and Yi-Chieh Lee", "conference": "ICLR 2025 Workshop on Human-AI Coevolution", "abstract": "As AI agents become increasingly interactive, their potential to shape human opinions raises concerns about bias reinforcement, misinformation, and manipulation. While prior research has examined how individual AI agents influence users, it remains unclear whether multi-agent AI systems exert stronger influence, similar to human group effects. Drawing on social influence theory, we investigate whether a group of AI agents can amplify opinion shifts compared to a single agent. In an empirical study where participants discussed two paintings with either one or five AI agents, we found that multi-agent interactions led to significantly stronger opinion shifts. Participants aligned more closely with the AI group's expressed stance, suggesting that increasing the number of agents enhances social influence. These findings highlight both the opportunities and risks of multi-agent AI in shaping user opinions, with implications for persuasive and ethical AI design. Additionally, we identified several factors that may moderate the influence of multi-agent AI, including users' prior beliefs on the topic, perceived in-authenticity of AI-generated comments, and alignment between human and AI preferences. Considering these factors in future AI system design could help balance influence effectiveness with user autonomy and trust."}, "filled": true, "author_pub_id": "J1cg8fIAAAAJ:IjCSPb-OGe4C", "num_citations": 1, "citedby_url": "/scholar?cites=7754410309846802175", "cites_id": ["7754410309846802175"], "pub_url": "https://openreview.net/forum?id=6zlttMWe4G", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:_54LmRcznWsJ:scholar.google.com/", "cites_per_year": {"2025": 1}}, "J1cg8fIAAAAJ:u-x6o8ySG0sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Transformer Fault Diagnosis Based on PSO-RF Characterised by Modified CNN-encoder", "pub_year": 2022, "author": "Maojia Song and Yicheng Luo and Shixiao Liu and Jingwei Fan and Mingyue Li and Dong Liu", "conference": "2022 IEEE 11th Data Driven Control and Learning Systems Conference (DDCLS)", "pages": "300-305", "publisher": "IEEE", "abstract": "Oil-immersed transformer is one of the most important pieces of equipment in the power grid. Improving the performance of such transformer fault diagnosis to ensure a more stable power system is of great significance to safe operation. By analysing dissolved gases in oil, a fault diagnosis model based on Particle Swarm optimised Random Forest (PSO-RF), with features integrated by an improved CNN-encoder, is proposed. Firstly, the raw volume fraction of dissolved gases is processed by 1-dim Convolutional layers to form new combined features by machine. Secondly, current popular coded methods are integrated to produce final effective features that are sorted to obtain at least 90% of the information. Finally, feature vectors are applied to the fault diagnosis model based on PSO-RF. The experimental results show that the accuracy of the diagnosis model is achieved by 93.33% in the test set. Compared with â€¦"}, "filled": true, "author_pub_id": "J1cg8fIAAAAJ:u-x6o8ySG0sC", "num_citations": 1, "citedby_url": "/scholar?cites=6175682971576350721", "cites_id": ["6175682971576350721"], "pub_url": "https://ieeexplore.ieee.org/abstract/document/9858389/", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:Abg8RvFutFUJ:scholar.google.com/", "cites_per_year": {"2023": 1}}, "J1cg8fIAAAAJ:9yKSN-GCB0IC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "FusionNet: a new perspective of CNN for image classification", "pub_year": 2022, "author": "Maojia Song", "conference": "2022 3rd International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering (ICBAIE)", "pages": "639-647", "publisher": "IEEE", "abstract": "The civil livelihood plan is related to corn, or maize, as one of the most significant grain products that suffers from various kinds of diseases, resulting in a decline in production. Traditional manual examination for disease in terms of prevention and control is time-consuming with low efficiency. Therefore, this paper proposes a new architecture called FusionNet fully based on deep convolution network to improve the speed and accuracy of the classification of various maize diseases. Using focus splitting, identity shortcut, and multi-feature channel fusion, this model presents a new consideration of larger kernels utilized in concatenated for features that offer more effective receptive fields to facilitate the reduction of reused redundancy, especially for middle-layer abstract information, which could compensate for the shortage of feature selectivity of CNN. Moreover, the total number of parameters is limited by depth-wise â€¦"}, "filled": true, "author_pub_id": "J1cg8fIAAAAJ:9yKSN-GCB0IC", "num_citations": 1, "citedby_url": "/scholar?cites=15401652434721508861", "cites_id": ["15401652434721508861"], "pub_url": "https://ieeexplore.ieee.org/abstract/document/9985910/", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:_Q2btUmpvdUJ:scholar.google.com/", "cites_per_year": {"2024": 1}}, "J1cg8fIAAAAJ:u5HHmVD_uO8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "The Mind Commands You: Combining Brain-Computer Interactions with Augmented Reality to Control Internet of Things (IoT) Tools, and Robotic Platforms", "pub_year": 2022, "author": "Wang Haohong and Gao Shenghao and Zhao Yimin and Song Maojia and Wang Heng and Damien Constantine Rompapas", "conference": "2022 IEEE 5th International Conference on Electronics Technology (ICET)", "pages": "1026-1031", "publisher": "IEEE", "abstract": "Many researchers are exploring the use of Brain Computer Interfaces (BCI) in combination with Internet of Things (IoT) tools, and robotic control. However, the training and application process for BCI controls can be difficult to achieve partially due to the required double-attention of both the target matter, and the on screen feedback loop used during training. Enter Augmented Reality (AR), a technique for embedding computer generated content (CG) in the userâ€™s view of the environment. In this research, we describe a system that explores the combination of a BCI training environment with AR technologies for both training and run time usage. We show the key advantage of this combination, allowing the user to focus directly on the subject matter. While our work is in the prototype phase, we show that this combination of AR and BCI has the potential to be effective in the training and usage of BCI interfaces."}, "filled": true, "author_pub_id": "J1cg8fIAAAAJ:u5HHmVD_uO8C", "num_citations": 1, "citedby_url": "/scholar?cites=3343742152868183973", "cites_id": ["3343742152868183973"], "pub_url": "https://ieeexplore.ieee.org/abstract/document/9824583/", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:pT81qsVbZy4J:scholar.google.com/", "cites_per_year": {"2024": 1}}, "J1cg8fIAAAAJ:YsMSGLbcyi4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Demystifying deep search: a holistic evaluation with hint-free multi-hop questions and factorised metrics", "pub_year": 2025, "author": "Maojia Song and Renhang Liu and Xinyu Wang and Yong Jiang and Pengjun Xie and Fei Huang and Soujanya Poria and Jingren Zhou", "journal": "arXiv preprint arXiv:2510.05137", "abstract": "RAG (Retrieval-Augmented Generation) systems and web agents are increasingly evaluated on multi-hop deep search tasks, yet current practice suffers from two major limitations. First, most benchmarks leak the reasoning path in the question text, allowing models to follow surface cues rather than discover reasoning chains autonomously. Second, evaluation is typically reduced to a single pass rate, which collapses diverse behaviours into one score and obscures whether failures stem from inadequate search, poor knowledge use, or inappropriate refusal. To address these issues, we present WebDetective, a benchmark of hint-free multi-hop questions paired with a controlled Wikipedia sandbox that ensures full traceability of model actions, and a holistic evaluation framework that separates search sufficiency, knowledge utilisation, and refusal behaviour. Our evaluation of 25 state-of-the-art models reveals systematic weaknesses across all architectures: models struggle with knowledge utilisation despite having sufficient evidence and demonstrate near-absent appropriate refusal when evidence is lacking. These patterns expose a fundamental gap: today's systems excel at executing given reasoning paths but fail when required to discover them. We develop an agentic workflow, EvidenceLoop, that explicitly targets the challenges our benchmark identifies, incorporating verification loops and systematic evidence tracking that improve both search and synthesis capabilities. This baseline demonstrates that WebDetective's diagnostic framework can guide concrete architectural improvements, establishing our benchmark as a critical tool for â€¦"}, "filled": true, "author_pub_id": "J1cg8fIAAAAJ:YsMSGLbcyi4C", "num_citations": 0, "pub_url": "https://arxiv.org/abs/2510.05137", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:NwrlQXzY4yQJ:scholar.google.com/", "cites_per_year": {}}, "J1cg8fIAAAAJ:UeHWp8X0CEIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "PromptDistill: Query-based Selective Token Retention in Intermediate Layers for Efficient Large Language Model Inference", "pub_year": 2025, "author": "Weisheng Jin and Maojia Song and Tej Deep Pala and Yew Ken Chia and Amir Zadeh and Chuan Li and Soujanya Poria", "journal": "arXiv preprint arXiv:2503.23274", "abstract": "As large language models (LLMs) tackle increasingly complex tasks and longer documents, their computational and memory costs during inference become a major bottleneck. To address this, we propose PromptDistill, a novel, training-free method that improves inference efficiency while preserving generation quality. PromptDistill identifies and retains the most informative tokens by leveraging attention interactions in early layers, preserving their hidden states while reducing the computational burden in later layers. This allows the model to focus on essential contextual information without fully processing all tokens. Unlike previous methods such as H2O and SnapKV, which perform compression only after processing the entire input, or GemFilter, which selects a fixed portion of the initial prompt without considering contextual dependencies, PromptDistill dynamically allocates computational resources to the most relevant tokens while maintaining a global awareness of the input. Experiments using our method and baseline approaches with base models such as LLaMA 3.1 8B Instruct, Phi 3.5 Mini Instruct, and Qwen2 7B Instruct on benchmarks including LongBench, InfBench, and Needle in a Haystack demonstrate that PromptDistill significantly improves efficiency while having minimal impact on output quality compared to the original models. With a single-stage selection strategy, PromptDistill effectively balances performance and efficiency, outperforming prior methods like GemFilter, H2O, and SnapKV due to its superior ability to retain essential information. Specifically, compared to GemFilter, PromptDistill achieves an overall  to  â€¦"}, "filled": true, "author_pub_id": "J1cg8fIAAAAJ:UeHWp8X0CEIC", "num_citations": 0, "pub_url": "https://arxiv.org/abs/2503.23274", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:iSS8u4jomoAJ:scholar.google.com/", "cites_per_year": {}}}, "citedby5y": 60, "hindex": 4, "hindex5y": 4, "i10index": 3, "i10index5y": 3, "cites_per_year": {"2023": 2, "2024": 9, "2025": 48}, "updated": "2025-10-25 08:20:16.707044"}