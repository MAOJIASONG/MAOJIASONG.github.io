---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<!-- 
  Tags:
  The id needs to be uncommented for use, if don't use, must comment it.
  <span id='total_cit'> autoupdate </span>
  <span id='5y_cit'> autoupdate </span>
  <span id='hindex'> autoupdate </span>
  <span id='5y_hindex'> autoupdate </span>
  <span id='i10index'> autoupdate </span>
  <span id='5y_i10index'> autoupdate </span>
  <span id='cites_per_year'> autoupdate </span>
  <span id='affiliation'> autoupdate </span>
  <span id='interests'> autoupdate </span>
  <a class='scholar_url' href=''> autoupdate </span>
  <a class='paper_title' href='' data='DhtAFkwAAAAJ:ALROH1vI_8AC(paper_id)'></a>
  <span class='paper_author' data='DhtAFkwAAAAJ:ALROH1vI_8AC(paper_id)'></span>
  <span class='paper_conference' data='DhtAFkwAAAAJ:ALROH1vI_8AC(paper_id)'></span>
  <span class='paper_year' data='DhtAFkwAAAAJ:ALROH1vI_8AC(paper_id)'></span>
  <span class='paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC(paper_id)'></span>
 -->

<span class='anchor' id='about-me'></span>





<!-- Intro -->
<!-- self introduction -->
Hello! Welcome to my homepage. Currently, I am advised by Prof. [Soujanya Poria](https://sporia.info/) and focus on [undefined]. ***Want academic cooperation?*** Feel free to contact me at [unknown](mailto:smj812855@163.com).

<!-- education background -->
I am graduated from [School of Electronic and Electrical Engineering](https://eps.leeds.ac.uk/electronic-engineering) @University of Leeds <img src='../images/UoL.png' style="width: 5em;"> with a bachelor's degree. <!-- other collaboration -->

<!-- experience -->
I have conducted many projects related to deep learning, including:

- **Brain-controlled multifunctional rolling robot based on OpenBCI-AR and "Disk" system**.
- **Fault detection of high-speed subway sleepers based on images and deep learning algorithms**.
- **Intelligent inspection of key equipment in substations based on edged deep learning**.
- **Fault diagnosis of Oil-immersed transformers based on DGA (dissolved gas analysis)**.
- **Research internship in Deep Reinforcement Learning, and Image Segmentation at the University of Cambridge**.
- **Artificial Intelligence Internship Programme in NTU Business AI Lab**.
- **Production and practice of self-navigable buggy based on ROS, SLAM, and Object Detection**.
- **The research of Self-organised critical phase transformation of historical time sequences of power system based on Critical slowing down theory**.

For more detailes, Please see my [CV](../files/CV.pdf).

<!-- Awards -->


<!-- Interests -->
My research interest includes <strong><span id='my_interests'><!-- autoupdate --></span></strong>. I have published some related papers <a class='scholar_url' href=''><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>. 
<!-- at the top international AI conferences. -->

# üå† My Wish
I am curious about the construction of self-sustained AI agents, which requires many prevailing technologies, including Large language models, Human-in-the-loop, the world model, and even adaptive intelligence. The idea can be simply explained: self-sustaining AI should learn by himself from the environment constantly and is able to rebuild other related constitutes from the provided abstract representations of the same identity. It forces self-sustained AI to adaptively face the world, rather than only finding a one-fits-all solution. The foundation of its external performance should rely on the understanding of abstract representations to transform the real world into a digital world. Based on the previous development, the agents of an applicable system can thereby help this basic self-sustained AI to achieve embodied interaction with humans.





<!-- News -->
# üî• News
<!-- - *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->




<!-- Pub -->
# üìù Publications 

<!-- <div class='paper-box'>
  <div class='paper-box-image'>
    <div><div class="badge">CVPR 2016</div><img src='images/500x300.png' alt="sym" width="100%"></div>
  </div>
  <div class='paper-box-text' markdown="1">

  [Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)

  **Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun

  [**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) 
  <strong><span class='paper_citations' data='J1cg8fIAAAAJ:u-x6o8ySG0sC'></span></strong>
  <strong><span class='paper_year' data='J1cg8fIAAAAJ:u-x6o8ySG0sC'></span></strong>

  - Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
  </div>
</div> -->

<!-- - <span style="color:red;">(Oral)</span> `NeurIPS 2022` [M4Singer: a Multi-Style, Multi-Singer and Musical Score Provided Mandarin Singing Corpus](), Lichao Zhang, Ruiqi Li, Shoutong Wang, Liqun Deng, Jinglin Liu, **Yi Ren**, Jinzheng He, Rongjie Huang, Jieming Zhu, Xiao Chen, Zhou Zhao, *(Datasets and Benchmarks Track)* [![](https://img.shields.io/github/stars/M4Singer/M4Singer?style=social&label=Dataset+Stars)](https://github.com/M4Singer/M4Singer)   -->

- <strong><a class='paper_title' href='' data='J1cg8fIAAAAJ:u-x6o8ySG0sC'></a></strong>  
  <span class='paper_author' data='J1cg8fIAAAAJ:u-x6o8ySG0sC'></span>  
  <span class='paper_conference' data='J1cg8fIAAAAJ:u-x6o8ySG0sC'></span>  
  <strong><span class='paper_citations' data='J1cg8fIAAAAJ:u-x6o8ySG0sC'></span></strong><strong><span class='paper_year' data='J1cg8fIAAAAJ:u-x6o8ySG0sC'></span></strong>.

- <strong><a class='paper_title' href='' data='J1cg8fIAAAAJ:d1gkVwhDpl0C'></a></strong>  
  <span class='paper_author' data='J1cg8fIAAAAJ:d1gkVwhDpl0C'></span>  
  <span class='paper_conference' data='J1cg8fIAAAAJ:d1gkVwhDpl0C'></span>  
  <strong><span class='paper_citations' data='J1cg8fIAAAAJ:d1gkVwhDpl0C'></span></strong><strong><span class='paper_year' data='J1cg8fIAAAAJ:d1gkVwhDpl0C'></span></strong>.

- <strong><a class='paper_title' href='' data='J1cg8fIAAAAJ:9yKSN-GCB0IC'></a></strong>  
  <span class='paper_author' data='J1cg8fIAAAAJ:9yKSN-GCB0IC'></span>  
  <span class='paper_conference' data='J1cg8fIAAAAJ:9yKSN-GCB0IC'></span>  
  <strong><span class='paper_citations' data='J1cg8fIAAAAJ:9yKSN-GCB0IC'></span></strong><strong><span class='paper_year' data='J1cg8fIAAAAJ:9yKSN-GCB0IC'></span></strong>.

- <strong><a class='paper_title' href='' data='J1cg8fIAAAAJ:u5HHmVD_uO8C'></a></strong>  
  <span class='paper_author' data='J1cg8fIAAAAJ:u5HHmVD_uO8C'></span>  
  <span class='paper_conference' data='J1cg8fIAAAAJ:u5HHmVD_uO8C'></span>  
  <strong><span class='paper_citations' data='J1cg8fIAAAAJ:u5HHmVD_uO8C'></span></strong><strong><span class='paper_year' data='J1cg8fIAAAAJ:u5HHmVD_uO8C'></span></strong>.





<!-- honers -->
# üéñ Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 





<!-- others -->
# üìñ Educations
- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)

# üíª Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.